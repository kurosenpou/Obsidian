#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Obsidian AI Agent MVP - æœ€å°é™ã®å®Ÿè£…
ã‚·ãƒ³ãƒ—ãƒ«ãªAIè«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ 
"""

import streamlit as st
import os
from pathlib import Path
import json
from datetime import datetime
from typing import List, Dict, Any
import PyPDF2
import io

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Obsidian AI - MVP",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ã‚·ãƒ³ãƒ—ãƒ«ãªCSS
st.markdown("""
<style>
    #MainMenu {visibility: hidden;}
    .stDeployButton {display:none;}
    footer {visibility: hidden;}
    #stDecoration {display:none;}
    
    .main > div {
        padding-top: 2rem;
        padding-left: 1rem;
        padding-right: 1rem;
    }
    
    .title-container {
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .user-message {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        border-left: 4px solid #0084ff;
    }
    
    .ai-message {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        border-left: 4px solid #ff6b35;
        border: 1px solid #e1e5e9;
    }
</style>
""", unsafe_allow_html=True)

class SimpleAIClient:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ - OpenAI APIã¾ãŸã¯ãƒ€ãƒŸãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.has_api = bool(self.api_key)
        
    def generate_response(self, prompt: str) -> str:
        """AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        if self.has_api:
            try:
                import openai
                openai.api_key = self.api_key
                
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a materials science expert specializing in thermomechanics and Taylor-Quinney coefficient research. Provide detailed, technical responses."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
                return response.choices[0].message.content
            except Exception as e:
                return f"API Error: {e}"
        else:
            # ãƒ€ãƒŸãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
            return self._generate_demo_response(prompt)
    
    def _generate_demo_response(self, prompt: str) -> str:
        """ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
        demo_responses = {
            "taylor": "The Taylor-Quinney coefficient (Î²) represents the fraction of plastic work converted to heat during deformation. Typically ranges from 0.8-0.95 for most metals.",
            "thermomechanics": "Thermomechanics studies the coupling between mechanical deformation and thermal effects in materials under loading conditions.",
            "materials": "Materials science focuses on understanding structure-property relationships in engineering materials.",
            "default": f"This is a demo response to your query: '{prompt[:50]}...'. In a full implementation, this would be answered by an AI model trained on materials science literature."
        }
        
        prompt_lower = prompt.lower()
        for key, response in demo_responses.items():
            if key in prompt_lower:
                return response
        
        return demo_responses["default"]

def extract_text_from_pdf(uploaded_file) -> str:
    """PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    try:
        pdf_reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.read()))
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text[:1000]  # æœ€åˆã®1000æ–‡å­—ã®ã¿
    except Exception as e:
        return f"PDFèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"

def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.markdown("""
    <div class="title-container">
        <h1>ğŸ”¬ Obsidian AI Agent MVP</h1>
        <p>Material Science Research Assistant - Minimal Viable Product</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ AI Chat", "ğŸ“ PDF Upload", "â„¹ï¸ About"])
    
    with tab1:
        show_chat_interface()
    
    with tab2:
        show_pdf_upload()
    
    with tab3:
        show_about()

def show_chat_interface():
    """AIãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "ai_client" not in st.session_state:
        st.session_state.ai_client = SimpleAIClient()
    
    # APIçŠ¶æ…‹è¡¨ç¤º
    if st.session_state.ai_client.has_api:
        st.success("âœ… OpenAI API connected")
    else:
        st.warning("âš ï¸ OpenAI API not found - using demo mode")
        st.info("Set OPENAI_API_KEY environment variable to enable full AI features")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.markdown(f"""
            <div class="user-message">
                <strong>ğŸ‘¤ You:</strong><br>
                {message["content"]}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="ai-message">
                <strong>ğŸ”¬ Obsidian AI:</strong><br>
                {message["content"]}
            </div>
            """, unsafe_allow_html=True)
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    user_input = st.text_input("Ask about materials science:", key="chat_input")
    
    if st.button("Send") and user_input:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
        with st.spinner("Thinking..."):
            ai_response = st.session_state.ai_client.generate_response(user_input)
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
        
        st.rerun()
    
    # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("Clear Chat"):
        st.session_state.messages = []
        st.rerun()

def show_pdf_upload():
    """PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½"""
    st.header("ğŸ“ PDF Document Processor")
    
    uploaded_file = st.file_uploader("Upload a PDF file", type="pdf")
    
    if uploaded_file is not None:
        st.success(f"âœ… File uploaded: {uploaded_file.name}")
        
        if st.button("Extract Text"):
            with st.spinner("Processing PDF..."):
                extracted_text = extract_text_from_pdf(uploaded_file)
            
            st.subheader("ğŸ“„ Extracted Text (Preview)")
            st.text_area("Content:", extracted_text, height=300)
            
            # ä¿å­˜ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            if st.button("Save to Knowledge Base"):
                # ç°¡å˜ãªãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                save_path = Path("uploaded_docs") 
                save_path.mkdir(exist_ok=True)
                
                with open(save_path / f"{uploaded_file.name}.txt", "w", encoding="utf-8") as f:
                    f.write(extracted_text)
                
                st.success(f"ğŸ’¾ Text saved to knowledge base!")

def show_about():
    """ã‚¢ãƒ—ãƒªæƒ…å ±"""
    st.header("â„¹ï¸ About Obsidian AI MVP")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ¯ MVP Features")
        st.markdown("""
        - âœ… Simple AI chat interface
        - âœ… PDF text extraction
        - âœ… Demo mode (no API required)
        - âœ… Clean, minimal UI
        - âœ… OpenAI API integration (optional)
        """)
        
        st.subheader("ğŸ”§ Technical Stack")
        st.markdown("""
        - **Frontend**: Streamlit
        - **AI**: OpenAI GPT-3.5 (optional)
        - **PDF**: PyPDF2
        - **Storage**: Local files
        """)
    
    with col2:
        st.subheader("ğŸš€ Quick Start")
        st.markdown("""
        1. **Chat**: Ask materials science questions
        2. **Upload**: Process PDF documents
        3. **API**: Set OPENAI_API_KEY for full features
        """)
        
        st.subheader("ğŸ¯ Next Steps")
        st.markdown("""
        - Add vector database for PDFs
        - Implement fine-tuned models
        - Add citation tracking
        - Expand knowledge domains
        """)
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    st.markdown("---")
    st.subheader("ğŸ’» System Status")
    
    status_cols = st.columns(3)
    with status_cols[0]:
        st.metric("UI Status", "ğŸŸ¢ Online")
    with status_cols[1]:
        ai_status = "ğŸŸ¢ API" if st.session_state.get("ai_client", SimpleAIClient()).has_api else "ğŸŸ¡ Demo"
        st.metric("AI Status", ai_status)
    with status_cols[2]:
        st.metric("PDF Processor", "ğŸŸ¢ Ready")

if __name__ == "__main__":
    main()
